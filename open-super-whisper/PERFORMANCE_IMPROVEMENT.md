# パフォーマンス改善ガイド 🚀

## 概要
Open Super Whisperの文字起こし速度を改善するための設定とベストプラクティスを説明します。

## 現在の改善内容

### 1. デフォルトモデルの変更
- **変更前**: Whisper Medium (769M parameters)
- **変更後**: Whisper Large V3 Turbo (809M parameters)
- **効果**: 最高の精度と速度のバランス

### 2. 短い音声用の最適化
- 10秒以下の音声: max_tokens = 64 (128から削減)
- 10-30秒の音声: max_tokens = 128 (256から削減)
- 30秒以上の音声: max_tokens = 256 (512から削減)

### 3. GPU最適化設定
- CUDA benchmark有効化
- TF32有効化（GPU使用時）
- 決定論的生成による高速化

## さらなる高速化のための設定

### 1. モデル選択の推奨
```
最高バランス: Whisper Large V3 Turbo (809M parameters)
高速優先: Whisper Tiny (39M parameters)
軽量バランス: Whisper Small (244M parameters)
高精度: Whisper Large V3 (1550M parameters)
```

### 2. カスタム語彙の最適化
- 必要最小限の語彙のみ設定
- 長いプロンプトは避ける
- システム指示も簡潔に

### 3. システム要件
- **GPU**: NVIDIA GPU推奨（大幅な高速化）
- **RAM**: 8GB以上推奨
- **CPU**: マルチコアCPU推奨

## 期待される改善効果

### 処理時間の目安
- **Whisper Tiny**: 2-5秒（6秒音声）
- **Whisper Base**: 3-7秒（6秒音声）
- **Whisper Small**: 5-10秒（6秒音声）
- **Whisper Large V3 Turbo**: 8-15秒（6秒音声）

### GPU使用時の追加効果
- CPU比で3-5倍の高速化
- バッチ処理の最適化
- メモリ使用量の最適化

## トラブルシューティング

### 1. メモリ不足エラー
- より軽量なモデルに変更
- カスタム語彙を削減
- システム指示を簡潔に

### 2. 処理が遅い場合
- GPU使用状況を確認
- モデルをより軽量なものに変更
- 音声ファイルの品質を確認

### 3. 精度が低下する場合
- より高精度なモデルに変更
- カスタム語彙を追加
- システム指示を調整

## 設定例

### 高速設定（開発・テスト用）
```python
# モデル: Whisper Tiny
# カスタム語彙: 最小限
# システム指示: なし
```

### バランス設定（通常使用）
```python
# モデル: Whisper Large V3 Turbo
# カスタム語彙: 必要最小限
# システム指示: 簡潔
```

### 高精度設定（重要文書用）
```python
# モデル: Whisper Large V3
# カスタム語彙: 充実
# システム指示: 詳細
```

## 更新履歴
- 2024-07-31: デフォルトモデルをLarge V3 Turboに設定（最高バランス）
- 2024-07-31: 短い音声用パラメータ最適化
- 2024-07-31: GPU最適化設定追加 